{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.6. 卷积神经网络（LeNet）\n",
    "## 6.6.1. LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 6, kernel_size=5, padding=2),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    torch.nn.Conv2d(6, 16, kernel_size=5),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(16 * 5 * 5, 120),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(120, 84),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(84, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([1, 6, 28, 28])\n",
      "Sigmoid output shape:\t torch.Size([1, 6, 28, 28])\n",
      "AvgPool2d output shape:\t torch.Size([1, 6, 14, 14])\n",
      "Conv2d output shape:\t torch.Size([1, 16, 10, 10])\n",
      "Sigmoid output shape:\t torch.Size([1, 16, 10, 10])\n",
      "AvgPool2d output shape:\t torch.Size([1, 16, 5, 5])\n",
      "Flatten output shape:\t torch.Size([1, 400])\n",
      "Linear output shape:\t torch.Size([1, 120])\n",
      "Sigmoid output shape:\t torch.Size([1, 120])\n",
      "Linear output shape:\t torch.Size([1, 84])\n",
      "Sigmoid output shape:\t torch.Size([1, 84])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((1, 1, 28, 28), dtype=torch.float32)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, \"output shape:\\t\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6.2. 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import helper\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = helper.load_data_fashion_mnist(batch_size, path = \"../data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于完整的数据集位于内存中，因此在模型使用GPU计算数据集之前，我们需要将其复制到显存中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy_gpu(net, data_iter, device = None):\n",
    "    '''使用GPU计算操作模型在数据集上的精度'''\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval() # 切换评估模式\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    metric = helper.Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric.add(helper.accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim\n",
    "\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    '''用GPU训练模型'''\n",
    "    def init_weight(m):\n",
    "        if type(m) == torch.nn.Linear or type(m) == torch.nn.Conv2d:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weight)\n",
    "    print('train on ', device)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    animator = helper.Animator(xlabel='epochs', xlim = [1, num_epochs],\n",
    "                                legend=['train_loss', 'train_acc', 'test_acc'])\n",
    "    timer, num_batchs = helper.Timer(), len(train_iter)\n",
    "    for epoch in range(num_epochs):\n",
    "        metric = helper.Accumulator(3)\n",
    "        net.train()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():       # 不更新梯度\n",
    "                metric.add(l * X.shape[0], helper.accuracy(y_hat, y), X.shape[0])\n",
    "            timer.stop()\n",
    "            train_l = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            if (i + 1) % (num_batchs // 5) == 0 or i == num_batchs - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batchs, train_l)\n",
    "                animator.add(epoch + (i + 1) / num_batchs, train_acc)\n",
    "            test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "            animator.add(epoch + 1, test_acc)\n",
    "        print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, 'f'test acc {test_acc:.3f}')\n",
    "        print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec 'f'on {str(device)}')\n",
    "    animator.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\helper.py:71: UserWarning: Attempting to set identical left == right == 1 results in singular transformations; automatically expanding.\n",
      "  self.axes.set_xlim(xlim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.322, train acc 0.100, test acc 0.100\n",
      "1678.1 examples/sec on cuda:0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr, num_epochs = 0.9, 1\n",
    "# 79m 5.9s(CPU更慢)\n",
    "train_ch6(net, train_iter, test_iter, num_epochs, lr, helper.GPU.try_gpu())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bf896dc9a96a1f05858648d8e08d4485cbbfeec133930887cfa661edfd77fd61"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import helper\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = helper.Loader.load_data_time_machine(batch_size, num_steps)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor([0, 2]), len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(10).reshape((2, 5))\n",
    "F.one_hot(X.T, 28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(vocab_size, num_hiddens, device):\n",
    "    num_inputs = num_outputs = vocab_size\n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape, device=device) * 0.01\n",
    "    # 隐藏层参数\n",
    "    W_xh = normal((num_inputs, num_hiddens))\n",
    "    W_hh = normal((num_hiddens, num_hiddens))\n",
    "    b_h = torch.zeros(num_hiddens, device=device)\n",
    "    # 输出层参数\n",
    "    W_hq = normal((num_hiddens, num_outputs))\n",
    "    b_q = torch.zeros(num_outputs, device=device)\n",
    "    # 附加梯度\n",
    "    params = [W_xh, W_hh, b_h, W_hq, b_q]\n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rnn_state(batch_size, num_hiddens, device):\n",
    "    return (torch.zeros((batch_size, num_hiddens), device=device), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(inputs, state, params):\n",
    "    # inputs的形状：(时间步数量，批量大小，词表大小)\n",
    "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    # X的形状：(批量大小，词表大小)\n",
    "    for X in inputs:\n",
    "        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)\n",
    "        Y = torch.mm(H, W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "    return torch.cat(outputs, dim=0), (H,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModelScratch: #@save\n",
    "    \"\"\"从零开始实现的循环神经网络模型\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, device,\n",
    "                 get_params, init_state, forward_fn):\n",
    "        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n",
    "        self.params = get_params(vocab_size, num_hiddens, device)\n",
    "        self.init_state, self.forward_fn = init_state, forward_fn\n",
    "\n",
    "    def __call__(self, X, state):\n",
    "        X = torch.nn.functional.one_hot(X.T, self.vocab_size).type(torch.float32)\n",
    "        return self.forward_fn(X, state, self.params)\n",
    "\n",
    "    def begin_state(self, batch_size, device):\n",
    "        return self.init_state(batch_size, self.num_hiddens, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 28]), 1, torch.Size([2, 512]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hiddens = 512\n",
    "net = RNNModelScratch(len(vocab), num_hiddens, helper.GPU.try_gpu(), get_params,\n",
    "                      init_rnn_state, rnn)\n",
    "state = net.begin_state(X.shape[0], helper.GPU.try_gpu())\n",
    "Y, new_state = net(X.to(helper.GPU.try_gpu()), state)\n",
    "Y.shape, len(new_state), new_state[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ch8(prefix, num_preds, net, vocab, device):  #@save\n",
    "    \"\"\"在prefix后面生成新字符\"\"\"\n",
    "    state = net.begin_state(batch_size=1, device=device)\n",
    "    outputs = [vocab[prefix[0]]]\n",
    "    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))\n",
    "    for y in prefix[1:]:  # 预热期\n",
    "        _, state = net(get_input(), state)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(num_preds):  # 预测num_preds步\n",
    "        y, state = net(get_input(), state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time traveller h h h h h '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ch8('time traveller ', 10, net, vocab, helper.GPU.try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度裁剪\n",
    "def grad_clipping(net, theta):\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):\n",
    "    state, timer = None, helper.Timer()\n",
    "    metric = helper.Accumulator(2)\n",
    "    for X, Y in train_iter:\n",
    "        if state is None or use_random_iter:\n",
    "            state = net.begin_state(batch_size  = X.shape[0], device=device)\n",
    "        else:\n",
    "            if isinstance(net, torch.nn.Module) and not isinstance(state, tuple):\n",
    "                state.detach_()\n",
    "            else:\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "        y = Y.T.reshape(-1)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat, state = net(X, state)\n",
    "        l = loss(y_hat, y.long()).mean()\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            updater(batch_size = 1)\n",
    "        metric.add(l * y.numel(), y.numel())\n",
    "    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch8(net, train_iter, vocab, lr, num_epochs, device, use_random_iter = False):\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    animator = helper.Animator(xlabel='epoch', ylabel='perplexity', legend=['train'], xlim=[10, num_epochs])\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        updater = torch.optim.SGD(net.parameters(), lr)\n",
    "    else:\n",
    "        updater = lambda batch_size: helper.sgd(net.params, lr, batch_size)\n",
    "    predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)\n",
    "    for epoch in range(num_epochs):\n",
    "        ppl, speed = train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(predict('time traveller'))\n",
    "            animator.add(epoch + 1, [ppl])\n",
    "    print(f'困惑度 {ppl:.1f}, {speed:.1f} 词元/秒 {str(device)}')\n",
    "    print(predict('time traveller'))\n",
    "    print(predict('traveller'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time traveller the the the the the the the the the the the the t\n",
      "time travellere the the the the the the the the the the the the \n",
      "time traveller the the the the the the the the the the the the t\n",
      "time traveller and the the the the the the the the the the the t\n",
      "time travellere the the the the the the the the the the the the \n",
      "time traveller and the the this the this the thime that in the t\n",
      "time travellere the the the the the the the the the the the the \n",
      "time traveller and he pare the thice and he paree thave the thic\n",
      "time traveller and and the the the the the the the the the the t\n",
      "time traveller and and and and and and and and and and and and a\n",
      "time traveller at and he pare he the the the the the the the the\n",
      "time traveller and the the the the the the the the the the the t\n",
      "time traveller andeas at he the that hes in that hes in that hes\n",
      "time traveller and the perely the ond and the and the medical ma\n",
      "time traveller and the this that ie sime time time time time tim\n",
      "time traveller of the ream and of the reat we sone there whare a\n",
      "time travellericcensthill that is that se so that is mect and hi\n",
      "time traveller of d and and thit tha thiththas is the tid the mi\n",
      "time traveller triccentlor mas a wiverad enly in a sextonl was o\n",
      "time traveller of coud in time trace this sain the toried try we\n",
      "time traveller of ericin ancandiscently inconor way ove now he c\n",
      "time travelleringsain the tinn of stace hure as in all orestous \n",
      "time traveller of conce ond ching it t aco he toatee to chenothe\n",
      "time traveller but now you be another dame fion the sing a ree h\n",
      "time traveller procee thateller ha dimentions if ris four dimens\n",
      "time traveller after and the travellerscond move nettime provinc\n",
      "time travelleris we far her another way eat filly peredint mert \n",
      "time traveller ofler ablitatily frimmytinn alwithis to yom thee \n",
      "time traveller hed re ig there is the futmericeland yhust meacle\n",
      "time traveller but now you begin to seetit on very thing withoub\n",
      "time travellerit s against reason said filbyicat op chatrime tic\n",
      "time travellerit s against reason said filby but you willnever t\n",
      "time traveller but now you begin to seethe object of my investig\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time travellerit would be remarkably convenient for the historia\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time traveller of crid lonas he shitled iny time at whothabogo b\n",
      "time traveller after the pauserequired for the proper assimilati\n",
      "time traveller ffr seiit bat lofe butt andine sort ps heant brea\n",
      "time traveller fftly is all riof laicod all the wild ackmaled th\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time traveller with a slight accession ofcheerfulness really thi\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "困惑度 1.0, 70760.5 词元/秒 cuda:0\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "traveller with a slight accession ofcheerfulness really thi\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs, lr = 500, 1\n",
    "train_ch8(net, train_iter, vocab, lr, num_epochs, helper.GPU.try_gpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5285dd86b1a1b9eefb8e6b22eadc9e8c9cfa7142ff11ff14f45d2bf734aec44f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
